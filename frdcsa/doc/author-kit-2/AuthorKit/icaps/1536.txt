Proceedings of the Twentieth International Conference on Automated Planning and Scheduling (ICAPS 2010)

Pattern Database Heuristics for Fully Observable Nondeterministic Planning
University of Freiburg, Germany, {mattmuel,ortlieb,helmert}@informatik.uni-freiburg.de

¨ Robert Mattmuller and Manuela Ortlieb and Malte Helmert

Pascal Bercher
University of Ulm, Germany, pascal.bercher@uni-ulm.de

Abstract
When planning in an uncertain environment, one is often interested in ﬁnding a contingent plan that prescribes appropriate actions for all possible states that may be encountered during the execution of the plan. We consider the problem of ﬁnding strong cyclic plans for fully observable nondeterministic (FOND) planning problems. The algorithm we choose is LAO*, an informed explicit state search algorithm. We investigate the use of pattern database (PDB) heuristics to guide LAO* towards goal states. To obtain a fully domainindependent planning system, we use an automatic pattern selection procedure that performs local search in the space of pattern collections. The evaluation of our system on the FOND benchmarks of the Uncertainty Part of the International Planning Competition 2008 shows that our approach is competitive with symbolic regression search in terms of problem coverage, speed, and plan quality.

Introduction
For an agent planning in an uncertain environment it is not always sufﬁcient to simply assume that all its actions will succeed and to replan upon failure. Rather, it can be advantageous to compute a contingent plan that prescribes actions for all possible states resulting from nondeterministic action outcomes completely ahead of execution. Speciﬁcally, in this work, we are concerned with ﬁnding strong cyclic plans (Cimatti et al. 2003) for fully observable nondeterministic (FOND) planning problems. Whereas strong plans, i.e., plans guaranteed to lead to a goal state in a ﬁnite number of steps, can be found using AO* search (Martelli and Montanari 1973), LAO* search (Hansen and Zilberstein 2001) is better suited to ﬁnd strong cyclic plans, i.e., plans that may loop indeﬁnitely as long as they do not contain dead ends and there is always a chance of making progress towards the goal. As shown in earlier work (Hoffmann and Brafman 2005; Bryce, Kambhampati, and Smith 2006; Bercher and Mattm¨ ller 2008), using AO* (or LAO*) in conjunction u with an informative heuristic can be an efﬁcient way to ﬁnd contingent plans of high quality. Most heuristic search planners for nondeterministic problems use a delete relaxation heuristic to guide the search. Since it is not straightforward
Copyright c 2010, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved.

to make delete relaxations take the nondeterminism into account properly, in this work we investigate the use of pattern database (PDB) heuristics (Culberson and Schaeffer 1998; Edelkamp 2001). The abstractions underlying the PDBs can be designed to preserve the original nondeterminism. We use local search in the space of pattern collections (Haslum et al. 2007) to obtain suitable PDBs. The contribution of this paper consists of the application of PDB heuristics to domain-independent strong cyclic planning, the deﬁnition of a suitable abstraction mapping, deﬁnitions of abstract costs and their computation, as well as an implementation and empirical evaluation of the resulting planning algorithm in comparison to Gamer (Kissmann and Edelkamp 2009), a planner that performs BDD-based planning as model checking (Cimatti et al. 2003). Minor contributions are the adaptations of a ﬁnite-domain representation of planning problems and of a pattern selection algorithm from the deterministic to the nondeterministic context.

Preliminaries
FOND SAS Planning Tasks
We assume that the planning problem is given in a ﬁnitedomain representation that can be obtained from Probabilistic PDDL (PPDDL) using an adaptation of Helmert’s PDDL-to-SAS+ translation algorithm (2009). A fully observable nondeterministic SAS+ (B¨ ckstr¨ m a o and Nebel 1995) planning task is a tuple Π = V, s0 , s , O consisting of the following components: V is a ﬁnite set of state variables v, each with a ﬁnite domain Dv and an ex+ tended domain Dv = Dv {⊥}, where ⊥ denotes the undeﬁned or don’t-care value. A partial state is a function s + with s(v) ∈ Dv for all v ∈ V. We say that s is deﬁned for v ∈ V if s(v) = ⊥. A state is a partial state s that is deﬁned for all v ∈ V. The set of all states s over V is denoted as S. Depending on the context, a partial state sp can be interpreted either as a condition, which is satisﬁed by a state s iff s agrees with sp on all variables for which sp is deﬁned, or as an update on a state s, resulting in a new state s that agrees with sp on all variables for which sp is deﬁned, and with s on all other variables. The initial state s0 of a problem is a state, and the goal description s is a partial state. O is a ﬁnite set of actions of the form a = Pre, Eﬀ , where the precondition Pre is a partial state, and the effect Eﬀ
+

105

is a ﬁnite set of partial states eﬀ , the nondeterministic outcomes of a. The application of a nondeterministic outcome eﬀ to a state s is the state app(eﬀ , s) that results from updating s with eﬀ . The application of an effect Eﬀ to s is the set of states app(Eﬀ , s) = {app(eﬀ , s) | eﬀ ∈ Eﬀ } that might be reached by applying a nondeterministic outcome from Eﬀ to s. An action is applicable in s iff its precondition is satisﬁed in s. The application of a to s is app(a, s) = app(Eﬀ , s) if a is applicable in s, and undeﬁned otherwise. All actions have unit cost.

Strong and Strong Cyclic Planning
The semantics of a planning task Π = V, s0 , s , O can be deﬁned via AND/OR graphs over the states S. An AND/OR graph G = N, C consists of a set of nodes N and a set of connectors C, where a connector is a pair n, M , connecting the parent node n ∈ N to a nonempty set of children M ⊆ N . A (directed) path in G is a sequence of nodes successively linked by connectors. Often, an AND/OR graph contains a distinguished initial node n0 ∈ N and a set of goal nodes N ⊆ N . The strong preimage of a set of nodes X ⊆ N is the set of connectors that are guaranteed to lead to a node in X, and the weak preimage of X is the set of connectors that may lead to a node in X. Formally, spre(X) = { n, M ∈ C | M ⊆ X} and wpre(X) = { n, M ∈ C | M ∩ X = ∅}. We write N (C ) = {n ∈ N | ∃M ⊆ N : n, M ∈ C } to denote the set of nodes with an outgoing connector in C ⊆ C. A subgraph of an AND/OR graph G is an AND/OR graph G = N , C such that N ⊆ N and C only contains connectors from C whose involved nodes (parent and children) are contained in N . We usually require that the initial node n0 of G is contained in N as the initial node n0 of G , and that the set of goal nodes is N = N ∩ N . The following properties of a subgraph G of G are of interest: Acyclicity: G contains no path from n to n for any n ∈ N . Closedness: For all nongoal nodes n ∈ N \ N , there is exactly one outgoing connector c = n, M in C . Properness: For all nongoal nodes n ∈ N \ N , there is a ﬁnite path in G starting at n and ending in a goal node n ∈N . The AND/OR graph induced by Π is the graph G = N, C , where N is the set of states S of the planning task, and where there is one connector s, app(a, s) ∈ C for each state s and action a applicable in s leading from s to the states that might result from different nondeterministic outcomes of a. The initial node is n0 = s0 , and a node n is a goal node in N iff it satisﬁes the goal description s . A subgraph of the AND/OR graph induced by Π is called a strong cyclic plan if it is closed and proper, and a strong cyclic plan is called a strong plan if it is acyclic. A subgraph is a weak plan if it contains a path from n0 to a goal node. Strong cyclic plans (“trial-and-error strategies”) are a compromise between the overly optimistic view of weak plans

and the strict requirement of strong plans that an action that is supposed to be part of a plan may never completely fail or even repulse the agent away from the goal. Strong cyclic plans allow such actions, as long as there is some chance to move closer to the goal and no danger of ending up in a dead end. During the construction of a plan, an explicit graph G = N , C is maintained that is a connected subgraph of G with the property that for all nongoal nodes n, either all outgoing connectors from n in G are contained in C (n is expanded) or none of them is contained in C (n is unexpanded). A partial strong cyclic plan (partial strong plan) is a subgraph of the explicit graph that satisﬁes the properties of a strong cyclic plan (strong plan), with the exception that closedness is relaxed such that outgoing connectors are only required for expanded nongoal nodes and that properness is not required.

AO* and LAO* Search
The problems of ﬁnding a strong plan or a strong cyclic plan, given a planning task Π, can be solved by AO* and LAO* graph search, respectively. AO* search (Martelli and Montanari 1973) is an algorithm that gradually builds an explicit graph until a strong solution has been found or the graph has been completely generated. Starting from n0 , in each step, it ﬁrst extracts a partial solution by tracing down the most promising connectors, expands one or more of the unexpanded nongoal nodes encountered, and updates the information about which outgoing connectors are deemed most promising given the information obtained from the last expansion. The quality f of unexpanded nongoal nodes is estimated using a heuristic h, and in interior nodes, it is an aggregate of the qualities of the successor nodes. Whereas AO* is sufﬁcient to ﬁnd strong plans, strong cyclic plans can be found using an extension to AO* called LAO* (Hansen and Zilberstein 2001). Unlike AO*, which uses backward induction, LAO* uses a dynamic programming algorithm like policy iteration or value iteration to update node estimates, thus allowing it to ﬁnd solutions with loops as well, while still following a heuristic guidance. Pseudocode of (a variant of) LAO* is given in Algorithm 1. In the pseudocode, in which we assume that a solution exists, G is the implicit graph, G the explicit graph, and T RACE(G ) traces down marked connectors in G and returns the corresponding subgraph, which is considered incomplete if it still contains unexpanded nongoal nodes. These nodes are returned by U NEXPANDED N ON G OAL and then expanded simultaneously (E XPANDA LL), i.e., their successor nodes and corresponding connectors are incorporated into G . After initializing the cost estimates f of all new nodes, the subgraph Z of nodes to be updated is chosen as the portion of G weakly BACKWARD R EACHable from the freshly expanded nodes. While VALUE I TERATION is performed on Z, the algorithm maintains the invariant that for each expanded nongoal node, exactly one outgoing connector minimizing f is marked. Often, the search is equipped with a solve-labeling procedure that can be used to decide when a solution has been found and as a means of pruning the search space, since out-

106

Algorithm 1 LAO*(G) G ← n0 , ∅ while n0 unsolved do E ← U NEXPANDED N ON G OAL(T RACE (G )) if E = ∅ then E ← U NEXPANDED N ON G OAL(G ) Nnew ← E XPANDA LL(E) 0 if n ∈ N for all n ∈ Nnew f (n ) ← h(n ) otherwise Z ← BACKWARD R EACH (E) S OLVE L ABELING(G ) VALUE I TERATION(Z) return T RACE (G )

going connectors from solved nodes do not need to be traced down any more. In strong cyclic planning, a node can be marked as solved if it is a goal node or if there is an applicable action that has a chance of leading to a solved node and that is guaranteed not to lead to potential dead-end nodes. Technically, the solve-labeling procedure for strong cyclic planning is a nested ﬁxed point computation, outlined in Algorithm 2. Note that the outer loop computes a greatest ﬁxed point, whereas within that loop, ﬁrst the least ﬁxed point of the set of all connectors weakly backward-reachable from the goal nodes along solved connectors in Cs is computed, followed by the computation of the greatest ﬁxed point of the set of all connectors in Cs guaranteed not to lead outside of Cs . Algorithm 2 S OLVE L ABELING(G) Cs ← C while Cs has not reached a ﬁxed point do Cs ← { n, M ∈ C | M ∩ N = ∅} while Cs has not reached a ﬁxed point do Cs ← Cs ∪ (wpre(N (Cs )) ∩ Cs ) while Cs has not reached a ﬁxed point do Cs ← Cs ∩ spre(N (Cs ) ∪ N ) Cs ← Cs return N (Cs ) Given an informative heuristic, more promising parts of the graph are likely to be expanded before the less promising ones by AO* and LAO*, and irrelevant portions of the search space may never be explored before a solution is found.

depth d below the current node, then the size of any nondegenerate solution tree rooted at the current node and even more the search effort, will be exponential in d. Therefore, minimizing d helps minimizing the search effort. If the distance from the current node to the necessary goal nodes is not constant, then because of the tree shape, for complete nondegenerate trees it is the maximal goal distance that matters. Thus, for strong planning, a reasonable measure for the remaining search effort below a node n is the depth of a depth-minimizing solution for the subproblem corresponding to n. We cannot compute this depth directly without solving the whole subproblem, but using an estimator that returns the depth of a depth-minimizing plan for a simpliﬁed problem can be expected to provide useful guidance. However, there are still two questions to be answered: • What kind of simpliﬁcation should be used? • How can this estimate be adapted from strong to strong cyclic plans? To answer the ﬁrst question, note that in classical planning, the most important classes of simpliﬁcations are delete relaxations and projections. In nondeterministic planning, we additionally have the choice of whether or not to relax the nondeterminism and allow the agent not only to choose the action, but also its outcome among the possible nondeterministic outcomes. It is easy to come up with examples showing that relaxing nondeterminism can lead to heuristic estimates that guide the search in the wrong direction, whereas with the nondeterminism represented in the heuristic, the search is guided in the right direction. Therefore, we would like to retain nondeterminism in the relaxation. Since, unlike in combination with delete relaxation, this is straightforward with projections, for the rest of this work we answer the question what kind of simpliﬁcation to be used with projection to a subset of the state variables. To answer the second question, ﬁrst notice that in strong cyclic planning, the depth of a depth-minimizing plan is no longer well-deﬁned, since there may be inﬁnitely long paths in a plan. We can, however, make the simplifying assumption that all nondeterministic outcomes of the actions are equally likely, and replace the depth of a plan (the maximal number of steps to a goal) by the expected number of steps to a goal in order to obtain a well-deﬁned heuristic. We can express both variants of the heuristic (with maximum and expected value) in a Bellman formulation (Bellman 1957) as h(n) = 0 1+ min max h(n ) if n is a goal, otherwise, (1)

Heuristic Function
The performance of AO* and LAO* heavily depends on an appropriate heuristic estimator for unexpanded nongoal nodes. Our primary aim is to ﬁnd some plan fast rather than to ﬁnd an optimal plan, and hence the heuristic estimator we use does not necessarily have to accurately reﬂect remaining plan costs, but it should reﬂect the expected remaining search effort. If we assume tree search for a strong plan, a constant branching factor b of the connectors, and a constant goal

n,M ∈C n ∈M

in the case of maximization, and as h(n) = 0 1+
1 n,M ∈C |M| n ∈M

min

if n is a goal, h(n ) otherwise,

(2) for the expected value. It is easy to see that with maximization, h is guaranteed to give ﬁnite values for a node n iff there is a strong plan

107

starting in n. With expected values, h is guaranteed to have ﬁnite values for a node n iff there is a strong cyclic plan starting in n (i.e., if n can be marked as solved by the solvelabeling procedure for strong cyclic planning). The reason is that h(n) is the expected number of steps to a goal node using a strong cyclic plan minimizing that expected number, which must be ﬁnite, since a random walk of sufﬁcient ﬁnite length in the current strongly connected component (SCC) of the abstract state space always has a nonzero chance of making irreversible progress towards an SCC strictly closer to the goal, and there are only ﬁnitely many SCCs. The following examples show how the heuristic trades off plan lengths against chances of success and how states admitting “less cyclic” plans are preferred to states only admitting “more cyclic” plans. In both examples, n0 is the current (abstract) node, we use Eq. 2 to compute h-values, and we want to know which (abstract) action applicable in n0 is the most promising. Initial nodes are depicted with an incoming edge without source node, goal nodes with circles, and edges belonging to the same connector with a joining arc. • Strong vs. strong cyclic plans:

n1 a n0

b n2

Here, h(n1 ) = 1 and h(n2 ) = 1 + 1 (0 + h(n2 )), i.e., 2 h(n2 ) = 2. Therefore, the action a leading to a state admitting a strong subplan is preferred to the action b leading to a state only admitting a strong cyclic subplan. • Cyclicity of strong cyclic plans:

n1 a n0

b n2

Here, h(n1 ) = 1 + 1 (0 + 2 · h(n1)) and h(n2 ) = 1 + 1 (2 · 3 3 0 + h(n2 )), i.e., h(n1 ) = 3 and h(n2 ) = 3 , so the “less 2 cyclic” subplan is preferred. Note that this example is simpliﬁed for presentation, since the outgoing connector from n1 collapses to a connector n1 , M with |M | = 2 because of the set representation of successors.

Abstractions
Syntactic Projections
Pattern database heuristics are based on computing cost or search effort estimates in an abstract version of the original planning problem. In this section, we discuss syntactic projections for fully observable nondeterministic SAS+ planning tasks. A pattern is a subset P ⊆ V of the variables, and a pattern collection P ⊆ 2V is a set of patterns. The projection of a planning task Π to P is the task that results from Π if all variables outside of P are ignored, states are merged into one abstract state if they agree on all variables in P , and conditions and effects are restricted to P . Formally, the abstract task only contains the variables V↓P = V ∩ P ,

the projection s↓P of a (partial) state s is s restricted to P , i.e., s↓P (v) = s(v) for all v ∈ P , and projections of effects, actions, action sets and tasks are deﬁned elementwise and component-wise: Eﬀ ↓P = {eﬀ ↓P | eﬀ ∈ Eﬀ }, Pre, Eﬀ ↓P = Pre↓P , Eﬀ ↓P , O↓P = {a↓P | a ∈ O}, and V, s0 , s , O ↓P = V↓P , s0 ↓P , s ↓P , O↓P . We refer to states, connectors etc. from the state space of the original problem as concrete states, connectors etc., and to those from the projection as abstract states, connectors etc. By deﬁnition, the projection of a planning task is again a planning task. Its induced AND/OR graph is in general at most as large as the induced AND/OR graph of the original planning task. The syntactic projection has the property that it preserves action applicability, effect applications, and solvedness of states. More precisely, let s ∈ S be a concrete state, a = Pre, {eﬀ 1 , . . . , eﬀ n } a concrete action, solved the set of concrete states admitting a strong cyclic plan, and solved P the set of abstract states admitting a strong cyclic plan. Then (1) if a is applicable in s, then a↓P is applicable in s↓P , (2) app(eﬀ , s)↓P = app(eﬀ ↓P , s↓P ) and app(Eﬀ , s)↓P = app(Eﬀ ↓P , s↓P ), and (3) s ∈ solved implies s↓P ∈ solved P . Claims (1) and (2) immediately follow from the deﬁnition of projections. For (3), consider the solve-labeling procedure described in Algorithm 2. We call nodes in N (Cs ) solved, nodes in N (Cs ) after the ﬁrst and before the second inner loop connected, and nodes in N (Cs ) after the second inner loop safe. Initially, all concrete and abstract nodes are solved, so the induction base holds. In the i-th iteration of the outer loop, a concrete node n is marked as connected (in the ﬁrst inner loop) iff there is a ﬁnite path along nodes marked as solved in the previous iteration starting at n and ending in a goal node. Since, by (1) and (2), actions remain applicable in the abstraction and concrete successors are represented by abstract successors, and since, by induction hypothesis, solved concrete nodes are projected to solved abstract nodes, this sequence has an abstract counterpart showing that n↓P is connected as well. In the safe-labeling of the current iteration (the second inner loop), initially, all connected nodes are marked as safe, and a node is only removed from the safe nodes if all its outgoing connectors may potentially lead to an unsafe nongoal node. An abstract node n↓P is only removed from the abstract safe nodes if there is no abstract connector that guarantees staying in the abstract safe nodes. But then all corresponding concrete nodes n would be removed from the concrete safe nodes as well, for if there were a corresponding concrete node n and an outgoing connector c of n only leading to safe nodes, the projection of c to P would only lead to safe abstract nodes by induction hypothesis of the inner loop. Since the solved nodes in the next iteration are the remaining safe nodes, the induction step holds as well.

Pattern Database Heuristics
The abstractions and abstract costs or search effort estimates are precomputed before the actual search is performed. During the search, no costly calculations are necessary. The heuristic values are merely retrieved from the pattern database, in which the values of the abstract states have been stored during the preprocessing stage. Each ab-

108

straction is a projection of the original planning problem to a pattern P and deﬁnes a heuristic function hP . Since the size of the abstract state space grows exponentially in the size of the pattern P , reasonable patterns should not be too large. So, typically, one pattern will include only a small fraction of V, and hence the corresponding abstraction will completely ignore the contribution of many variables to the hardness of solving the problem that could be captured if the variables were included in P . Instead of using arbitrarily large patterns, one usually resorts to using several smaller patterns and aggregating the abstract costs of a state in the abstractions corresponding to the patterns. Given a ﬁnite collection P of patterns, one could deﬁne the heuristic function hP (n) = maxP ∈P hP (n). Since we want to maintain heuristic values as informative as possible, however, maximization is often not sufﬁcient and replacing maximization by summation could produce more informative heuristic values. On the other hand, adding h-values does not provide an additional advantage if the added heuristics reﬂect the contribution of the same or at least similar sets of actions, whereas other actions are still disregarded. Therefore, similarly to classical planning (Edelkamp 2001), we say that patterns P1 , . . . , Pk are additive if there is no action a = Pre, Eﬀ ∈ O that affects variables from more than one of the patterns, i.e., no action for which eﬀvars(Eﬀ )∩Pi = ∅ for more than one i = 1, . . . , k, where eﬀvars(Eﬀ ) = {v ∈ V | ∃eﬀ ∈ Eﬀ : eﬀ (v) = ⊥}. If the patterns in P are additive, we can deﬁne hP as hP (n) = P P ∈P h (n) instead of via maximization. Finally, given a set M of additive pattern collections, we can deﬁne the heuristic function hM (n) = maxP∈M P ∈P hP (n), which in general dominates all of the heuristics hP . Note that, unlike in optimal classical planning, where additivity is required to ensure admissibility of the resulting heuristic, we do not necessarily require additivity here, but rather use it as a means of getting an informative, not an admissible, heuristic, since additive pattern collections tend to cover action costs more accurately than collections of dependent or even overlapping patterns.

IDA* search with hP is lower than the expected number of C node expansions of an IDA* search with hP . C Algorithm 3 PATTERN S ELECTION(Π, bound ) P ← I NITIAL C OLLECTION(Π) while P < bound do S ← C HOOSE S AMPLES(Π) N ← N EIGHBORHOOD (P, Π) for all P ∈ N do δ(P ) ← I MPROVEMENT(P , P, S, Π) if δ(P ) = 0 for all P ∈ N then break P ← argmaxP ∈N δ(P ) return P The pattern selection presented as pseudocode in Algorithm 3 performs a hill-climbing search in the space of pattern collections, starting with the initial collection I NITIAL C OLLECTION(Π) that contains one singleton pattern for each variable occurring in the goal. The search continues until either there is no more improvement or the cumulative sizes of the pattern databases contained in the current pattern collection P exceed a given bound. The size of the pattern collection is P = P ∈P v∈P |Dv |. The N EIGHBORHOOD (P, Π) of the pattern collection P with respect to planning task Π contains a pattern collection P if there is a P ∈ P and a variable v ∈ P that is causally rel/ evant to P , such that P = P {P } for P = P ∪ {v}. The I MPROVEMENT(P , P, S, Π) of P over P with respect to the sample states in S is the estimated number of states s ∈ S for which hP returns a higher value than hP . C C This is precisely the number of states s ∈ S for which hP (s) > hP (s) − P ∈S\{P } hP (s) for some additive subset S ⊆ P that includes P . The algorithm terminates eventually, since P only increases in size and there are only ﬁnitely many different patterns. In each iteration, a call to C HOOSE S AMPLES(Π) is used to draw n sample states (non-uniformly) from the state space that are used to compute an estimate of how much guidance hP will provide. A sample is the last state on a random walk C through the state space, where successor states are selected uniformly at random among all possible successors. The length of the random walk is chosen uniformly between 0 and a ﬁxed upper bound d = 2 · hP (s0 ). C

Pattern Selection as Local Search
To determine the pattern collections P to be used, we use the local search algorithm by Haslum et al. (2007). Even though the evaluation function for pattern collections in their algorithm is based on the expected number of node expansions during IDA* search, not AO* or LAO* search, with the pattern collection under consideration, we believe that the patterns that are obtained that way are still useful in nondeterministic planning. The reasoning behind this is that the question whether variables are related closely enough to be grouped into one pattern is largely orthogonal to the question whether the actions in the planning task are deterministic. Let P be a pattern collection. Then the canonical heuristic function of P is the function hP = C maxP ∈M P ∈P hP , where M is the set of all maximal additive subsets of P. The pattern selection algorithm considers a pattern collection P to be better than a pattern collection P if the expected number of node expansions of an

Implementation Details
Abstract Cost Computation
Let P ⊆ V be a pattern and G = N, C the AND/OR graph induced by the projection of the given planning task to P . Then the abstract costs are deﬁned as the result of value iteration on the relevant part of G (Algorithm 4). Here, F ORWARD R EACH (G) builds the portion of G that is forward reachable from n0 , S OLVE L ABELING(G) labels solved nodes in G, and R ESTRICT T O S OLVED(G, solved ) restricts G to solved nodes. We have already shown that all forward reachable solved concrete states are represented by an abstract state that will be marked as solved . Therefore,

109

Algorithm 4 A BSTRACT C OST C OMPUTATION (G) G ← F ORWARD R EACH (G) solved ← S OLVE L ABELING(G) G ← R ESTRICT T O S OLVED (G, solved ) h (n) ← ∞ for all n ∈ N \ solved h (n) ← 0 for all n ∈ solved repeat h←h for all n ∈ solved \ N do 1 h (n) ← 1 + min |M| h(n )
n,M ∈C

Domain (probs) blocksworld (30) faults (55) ﬁrst-responders (100) forest (90) overall (275)

PDB 10 55 23 6 94

DR 10 54 24 6 94

0/1 10 33 19 3 65

Gamer 10 34 19 6 69

Table 1: Coverage of LAO* with PDB, delete relaxation, and 0/1 heuristic, compared to Gamer.
100 PDB 90 DR 80 0/1 70 Gamer 60 50 40 30 20 10 0 0.01 0.1

until maxn∈N |h (n) − h(n)| < ε return h

n ∈M

if we assign the heuristic value ∞ to all abstract states outside solved and prune the concrete search as soon as we encounter a concrete state s that maps to an abstract state s↓P with h(s↓P ) = ∞, the search remains complete. On the remaining solved abstract nodes, the algorithm performs value iteration until the error falls below ε, and eventually returns the cost function (including the mapping of unsolved abstract states to ∞). The value iteration is guaranteed to converge, since restricting the set of nodes on which value iteration is performed to those that are marked as solved guarantees that all cost values are bounded. Together with the fact that, starting with h ≡ 0, the Bellman update is a monotonically increasing function, this is sufﬁcient to ensure convergence and hence termination.

Coverage

1 10 Time (sec)

100

Figure 1: Coverage over time. strong cyclic planning (with LAO* replaced by AO* and simpler solve-labeling and abstract cost computation procedures) and only turn to strong cyclic planning after determining that no strong plan exists. The experiments were conducted on a 2 GHz Intel Pentium E2180 CPU with 1 GB memory limit. In order to obtain comparable search times and coverage values for the different conﬁgurations of our planner, two time limits were set independently for preprocessing including PDB computation (5 minutes) and search (15 minutes minus preprocessing time). Gamer was run with an overall time limit of 15 minutes.

Experiments
Setting and Benchmarks
We evaluated our planner on the benchmark problems of the IPC 2008 FOND track. The instances belong to the domains blocksworld, faults, ﬁrst-responders, and forest. We ran our planner with PDB heuristic, a variant of the FF heuristic (combining nondeterminism relaxation with delete relaxation) and the heuristic assigning 0 to goal nodes and 1 to all other nodes. We compared it to the winner of the FOND track 2008, Gamer (Kissmann and Edelkamp 2009), based on the criteria coverage (number of problems for which a strong cyclic plan was found), speed (time needed for each problem), plan size (number of state-action table entries), plan quality (expected number of steps to the goal under random selection of action outcomes), and guidance (number of nodes created by LAO*). The guidance criterion was only used in comparisons between different conﬁgurations of our planner, not when comparing against Gamer, which performs a symbolic search for which the guidance criterion is not meaningful. Since all problems solved by either planner only admit strong cyclic plans and no strong plans, we only report times needed to ﬁnd strong cyclic plans. In a setting where strong plans are the preferred solutions and a strong cyclic plan is only acceptable if no strong plan exists, our planner, like Gamer, could be conﬁgured to search for a strong plan ﬁrst, using the same search framework as described for

Results
We report the results obtained by our planner using 1000 samples in the pattern selection and convergence threshold ε = 10−4 in the value iteration (both in the evaluation of abstract states and in the value iteration subroutine of LAO*). Table 1 shows problem coverage per domain and overall after 15 minutes. Problems detected to be unsolvable by either planner are treated as if they were unsolved. Figure 1 shows the development of the coverage over time, with the PDB approach only gaining more covered instances after a longer preprocessing time and eventually catching up with the delete-relaxation approach. Table 2 shows times in seconds (t), LAO* node creations (n), and plan sizes (s), of our planner with PDB heuristic, our planner with delete relaxation heuristic, and with the 0/1 heuristic, as well as the times and plan sizes of Gamer, on

110

Problem bw-1 bw-2 bw-3 bw-4 bw-5 bw-6 bw-7 bw-8 bw-9 bw-10 faults-5-5 faults-6-4 faults-7-4 faults-8-3 faults-9-2 faults-9-3 faults-10-2 fr-1-6 fr-2-4 fr-4-3 fr-4-6 forest-2-5 forest-2-8

t 25.10 3.91 4.23 4.90 4.88 4.39 5.43 5.90 4.42 4.66 26.14 19.26 51.92 23.54 48.17 42.62 27.54 2.83 1.74 2.61 50.15 21.31 26.71

PDBs (tp , ts ) (25.05, 0.05) (3.83, 0.08) (4.09, 0.14) (3.80, 1.10) (4.27, 0.61) (3.98, 0.41) (3.93, 1.50) (4.15, 1.75) (4.41, 0.01) (4.25, 0.41) (26.09, 0.05) (18.42, 0.84) (42.01, 9.91) (19.55, 3.99) (20.66, 27.51) (39.61, 3.01) (27.19, 0.35) (0.34, 2.49) (1.15, 0.59) (1.02, 1.59) (1.15, 49.00) (16.14, 5.17) (21.55, 5.16)

s 11 9 17 17 16 11 25 14 8 13 65 124 280 275 135 429 167 8 8 10 13 59 59

n 43 293 931 8515 4899 2960 10277 14515 34 1988 329 5987 46964 26311 19533 23836 882 9776 1191 8060 139964 6378 6378

Delete relaxation t s n 0.20 10 50 0.28 9 293 0.48 17 931 4.84 32 23154 1.39 16 5968 0.87 11 2960 1.95 25 8549 1.84 16 8718 0.35 8 626 0.95 13 3080 0.73 65 509 1.75 135 7072 3.00 256 15152 4.76 276 26304 0.78 33 4049 9.03 407 49068 2.13 122 15012 2.27 8 9776 2.17 8 7780 2.19 10 8060 55.59 13 153742 13.43 56 4138 13.09 56 4138

0/1 heuristic t s n 0.16 13 296 0.07 9 92 0.85 19 2335 6.39 18 24406 0.92 22 3476 0.72 11 2710 1.28 24 5373 3.22 14 15754 0.29 8 534 0.89 13 3904 43.75 39 6138 35.03 29 13157 157.93 32 39895 58.39 29 32351 14.24 88 10996 240.82 49 82410 48.02 119 20358 119.56 8 7414 8.13 8 6400 24.66 10 20928 43.28 14 48384 229.22 59 6841 230.13 59 6843

Gamer t (tp , ts ) 220.73 (172.17, 48.56) 211.27 (170.28, 40.99) 206.07 (164.33, 41.74) 203.46 (156.60, 46.86) 202.66 (160.05, 42.61) 196.37 (158.49, 37.88) 198.17 (156.15, 42.02) 197.07 (155.70, 41.37) 203.51 (158.31, 45.20) 205.38 (161.01, 44.37) 168.35 (51.92, 116.43) 88.39 (29.52, 58.87) 25.34 (13.75, 11.59) 107.69 (38.45, 69.24) 24.48 (10.31, 14.17) 285.15 (111.77, 173.38) 84.25 (28.48, 55.77) 1.23 (0.75, 0.48) 38.31 (35.61, 2.70) 631.95 (527.59, 104.36) 249.51 (215.16, 34.35) 2.03 (1.52, 0.51) 1.90 (1.41, 0.49)

s 10 16 21 26 13 19 28 19 10 13 65 138 31 262 135 371 165 8 11 — — 56 56

Table 2: Times, plan sizes, and nodes created for LAO* with PDB, delete relaxation, and 0/1 heuristic, compared to Gamer. Dashes in the s column for Gamer indicate plan ﬁles too large to process. a subset of the benchmark problems solved by all four approaches, more speciﬁcally, the hard problems for which at least one algorithm needed more than 30 seconds to solve. In the case of PDB heuristics, the times for preprocessing (translation from PPDDL to FOND SAS+ and PDB computation, tp ) and search (ts ) are reported separately, with their sum shown in the overall times column (t). Translation times were always below 0.2 seconds. For Gamer, the times for preprocessing including reachability analysis (tp ) and search (ts ), excluding plan output time, are reported. The plan sizes reported for Gamer are not the numbers of policy entries in the plans Gamer produces, but rather the number of entries that remain after restricting the policy to the states reachable following the policy. This postprocessing decreases policy sizes by several orders of magnitude (e.g., for blocksworld instance #1 the number of policy entries drops from 428527 to 10). In the blocksworld domain, problems 1 to 10 are sufﬁciently simple to be solved by all planners, whereas the remaining 20 problems are too hard for all of them. On the solved problems, our planner outperforms Gamer in terms of search time, whereas plan sizes are similar. In the faults domain, the pure search time of our planner is mostly lower than that of Gamer. On the harder instances, even overall times of our planner, including PDB computation, are lower than the times needed by Gamer, and our coverage is noticeably higher. Again, plan sizes are similar. In the ﬁrst-responders domain, coverages and plan sizes are similar, and running times are very mixed. In the forest domain, all approaches except LAO*+0/1 solve the same six problems with similar plan sizes, with Gamer needing less time.

Problem bw-1 bw-2 bw-3 bw-4 bw-5 bw-6 bw-7 bw-8 bw-9 bw-10 faults-5-5 faults-6-4 faults-7-4 faults-8-3 faults-9-2 faults-9-3 faults-10-2 fr-1-6 fr-2-4 fr-4-3 fr-4-6 forest-2-5 forest-2-8

PDB 20.00 14.00 31.50 29.00 21.50 21.50 44.00 24.00 12.50 18.00 6.12 9.44 11.97 17.69 24.01 20.90 27.01 12.00 14.00 15.00 20.00 22.83 22.83

DR 15.00 14.00 31.50 33.75 21.50 21.50 44.00 28.00 12.50 18.00 6.12 8.94 11.75 17.70 25.00 21.92 30.97 12.00 14.00 15.00 20.00 24.00 24.00

0/1 56.00 14.00 21.25 32.00 21.50 21.50 46.00 24.00 12.50 18.00 8.00 13.00 16.00 21.00 26.12 22.50 30.97 12.00 14.00 15.00 20.00 22.83 22.83

Gamer 14.00 13.50 17.50 26.00 22.00 21.50 22.00 24.00 14.00 18.00 6.12 8.87 16.00 17.16 24.01 20.09 27.00 14.00 14.00 — — 22.00 22.00

Table 3: Plan qualities (expected numbers of steps to the goal under random selection of action outcomes) for LAO* with PDB, delete relaxation, and 0/1 heuristic, compared to Gamer. Note that this deﬁnition of plan quality differs from the IPC deﬁnition for strong acyclic solutions, i.e., worstcase number of steps to the goal. Dashes in the column for Gamer indicate plan ﬁles too large to process.

111

Nodes generated by LAO*

106 10
5

faults-9-5 faults-8-7 faults-6-6

often faster than LAO* search with PDB heuristic, if search and preprocessing time are added. However, because of the simple table look-up during search, pure search times are often lower with a PDB heuristic and the larger the problems become, the more this can compensate for the higher preprocessing times.

104 103 102

Acknowledgments
We thank Peter Kissmann for his assistance with Gamer and the anonymous reviewers for their helpful suggestions. This work was partly supported by the German Research Foundation (DFG) as part of the Transregional Collaborative Research Center “Automatic Veriﬁcation and Analysis of Complex Systems” (SFB/TR 14 AVACS, see www.avacs.org for more information), and as part of the Transregional Collaborative Research Center SFB/TRR 62 “Companion-Technology for Cognitive Technical Systems”.

0

5 10 Hill-climbing steps

Figure 2: Guidance dependent on number of local search steps in pattern selection procedure. Table 3 shows the expected numbers of steps to the goal under random selection of action outcomes of the plans found by the different approaches for the instances from Table 2. The results do not allow us to conclude that one of the approaches leads to signiﬁcantly better plans with respect to this quality measure. PDB heuristic and delete relaxation heuristic provide similar guidance to the search in all domains, and typically better guidance than the trivial 0/1 heuristic (Table 2 is biased towards problems for which LAO* with 0/1 heuristic accidentally appears well-guided, whereas considering all problems, the 0/1 heuristic provides a clearly worse guidance than PDBs and delete relaxation). In order to determine how different pattern collections guide the search, we interrupted the hill-climbing search in the space of pattern collections after k steps for increasing k and measured the guidance provided to LAO* by the current pattern collection after k steps. Figure 2 shows how the guidance improves with k for selected instances from the faults domain. Missing data points for small k indicate that LAO* timed out.

References
B¨ ckstr¨ m, C., and Nebel, B. 1995. Complexity results for a o SAS+ planning. Comput. Intell. 11(4):625–655. Bellman, R. 1957. Dynamic Programming. Princeton University Press. Bercher, P., and Mattm¨ ller, R. 2008. A planning graph u heuristic for forward-chaining adversarial planning. In ECAI’08, 921–922. Bryce, D.; Kambhampati, S.; and Smith, D. E. 2006. Planning graph heuristics for belief space search. JAIR 26:35–99. Cimatti, A.; Pistore, M.; Roveri, M.; and Traverso, P. 2003. Weak, strong, and strong cyclic planning via symbolic model checking. Artif. Intell. 147(1–2):35–84. Culberson, J. C., and Schaeffer, J. 1998. Pattern databases. Comput. Intell. 14(3):318–334. Edelkamp, S. 2001. Planning with pattern databases. In ECP’01, 13–24. Hansen, E. A., and Zilberstein, S. 2001. LAO*: A heuristic search algorithm that ﬁnds solutions with loops. Artif. Intell. 129(1–2):35–62. Haslum, P.; Botea, A.; Helmert, M.; Bonet, B.; and Koenig, S. 2007. Domain-independent construction of pattern database heuristics for cost-optimal planning. In AAAI’07, 1007–1012. Helmert, M. 2009. Concise ﬁnite-domain representations for PDDL planning tasks. Artif. Intell. 173(5–6):503–535. Hoffmann, J., and Brafman, R. I. 2005. Contingent planning via heuristic forward search with implicit belief states. In ICAPS’05, 71–80. Kissmann, P., and Edelkamp, S. 2009. Solving fullyobservable non-deterministic planning problems via translation into a general game. In KI’09, volume 5803 of LNCS, 1–8. Springer. Martelli, A., and Montanari, U. 1973. Additive AND/OR graphs. In IJCAI’73, 1–11.

Conclusion
We presented and evaluated a domain-independent planner for fully observable nondeterministic planning problems using LAO* search guided by a PDB heuristic. Our empirical evaluation suggests that heuristically guided progression search can be competitive with or even outperform uninformed symbolic regression search in terms of speed and coverage if an informative heuristic is used. The plans are of similar size and the expected numbers of steps to the goal when executing them, assuming uniform selection of action outcomes, are comparable as well. The comparison between delete relaxation heuristic and PDB heuristic shows that both heuristics guide the search similarly well, with PDB guidance signiﬁcantly improving with more time spent on the pattern selection. Also, the sizes and qualities of the plans found are comparable, whereas regarding speed, LAO* search with delete relaxation heuristic is

112

